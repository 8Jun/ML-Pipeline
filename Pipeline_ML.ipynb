{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/8Jun/ML-Pipeline/blob/master/Pipeline_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1vobuYjC9GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BdbhcDuDBCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0t3m9eEDF6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = pd.read_csv('clean_V6.csv')\n",
        "features = features.drop(columns=['ALLIANCE_LEVEL_ID', 'NET_SALES_UNITS', 'SOLD_TO_ID'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXoz09iMDMBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decimals = 2\n",
        "\n",
        "features['HEIGHT'] = (features['HEIGHT']/12).apply(lambda x: round(x, decimals))\n",
        "features['WIDTH'] = (features['WIDTH']/12).apply(lambda x: round(x, decimals))\n",
        "\n",
        "features['HEIGHT'] = features['HEIGHT'].astype(str)\n",
        "features[['HEIGHT_FT','HEIGHT_IN']] = features.HEIGHT.str.split('.', expand=True)\n",
        "\n",
        "features['WIDTH'] = features['WIDTH'].astype(str)\n",
        "features[['WIDTH_FT','WIDTH_IN']] = features.WIDTH.str.split('.', expand=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe0bREzKDQNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = features.drop(columns=['WIDTH', 'HEIGHT'])\n",
        "\n",
        "features[['HEIGHT_FT', 'HEIGHT_IN']] = features[['HEIGHT_FT', 'HEIGHT_IN']].astype(float)\n",
        "features[['WIDTH_FT', 'WIDTH_IN']] = features[['WIDTH_FT', 'WIDTH_IN']].astype(float)\n",
        "\n",
        "features[['HEIGHT_IN', 'WIDTH_IN']] = (features[['HEIGHT_IN', 'WIDTH_IN']]/12).apply(lambda x: round(x, decimals))\n",
        "\n",
        "features['SO_CREATED_DATE'] = features['SO_CREATED_DATE'].apply(pd.to_datetime)\n",
        "\n",
        "features['SO_CREATED_DATE'] = features['SO_CREATED_DATE'].astype(str)\n",
        "features[['SO_CREATED_DATE_Y', 'SO_CREATED_DATE_M', 'SO_CREATED_DATE_D']] = features.SO_CREATED_DATE.str.split('-', expand=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE4sQI5WDgDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_season(season):\n",
        "  if season['SO_CREATED_DATE_M'] in ['12','01','02']:\n",
        "    return 'W' #Winter\n",
        "  elif season['SO_CREATED_DATE_M'] in ['03','04','05']:\n",
        "    return 'S' #Spring\n",
        "  elif season['SO_CREATED_DATE_M'] in ['06','07','08']:\n",
        "    return 'SR' #Summer\n",
        "  else:\n",
        "    return 'F' #Fall\n",
        "\n",
        "features['SEASON'] = features.apply(lambda season: label_season(season), axis=1)\n",
        "\n",
        "features.head()\n",
        "\n",
        "#season_dict = {'12':'winter', '01':'winter', '02':'winter', '03':'spring', '04':'spring', '05':'spring', '06':'summer', '07':'summer', '08':'summer', '09':'fall', '10':'fall', '11':'fall'}\n",
        "#features['SEASON'] = features['SO_CREATED_DATE_M'].map(season_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BKIzDmH0DK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_states (row):\n",
        "    if row['REGION_STATE_ID'] in ['ME', 'NH', 'VE', 'MA', 'RI', 'CT', 'NY', 'PA', 'NJ']:\n",
        "      return 'NE' #Northeast\n",
        "    elif row['REGION_STATE_ID'] in ['WI', 'MI', 'IL', 'IN', 'OH', 'ND', 'SD', 'NE', 'KS', 'MN', 'IA', 'MO']:\n",
        "      return 'MW' #Midwest\n",
        "    elif row['REGION_STATE_ID'] in ['DE', 'MD', 'DC', 'VA', 'WV', 'NC', 'SC', 'GA', 'FL', 'KY', 'TN', 'MS', 'AL', 'OK', 'TX', 'AR', 'LA']:\n",
        "      return 'S' #South\n",
        "    else:\n",
        "      return 'W' #West\n",
        "\n",
        "features['REGION'] = features.apply(lambda row: label_states(row), axis=1)\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v02diTmUSrOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_height (height):\n",
        "  if height['HEIGHT_FT'] in ['0.0','1.0','2.0','3.0']:\n",
        "    return 'S' #Small\n",
        "  elif height['HEIGHT_FT'] in ['4.0','5.0','6.0']:\n",
        "    return 'M' #Medium\n",
        "  else:\n",
        "    return 'L' #Large\n",
        "\n",
        "features['HEIGHT_bin'] = features.apply(lambda height: label_height(height), axis=1)\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnq3tmEMT8gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_width (width):\n",
        "  if width['WIDTH_FT'] in ['1','2','3','4']:\n",
        "    return 'S' #Small\n",
        "  elif width['WIDTH_FT'] in ['5','6','7','8']:\n",
        "    return 'M' #Medium\n",
        "  else:\n",
        "    return 'L' #Large\n",
        "\n",
        "features['WIDTH_bin'] = features.apply(lambda width: label_width(width), axis=1)\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjjzZ1W8DiqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = features.reindex(columns=['REGIONAL_SALES_MGR_ID','REGION_STATE_ID','FABRIC_ID','ORIGINAL_MATERIAL_ID','SO_CREATED_DATE','HEIGHT_FT','HEIGHT_IN','HEIGHT_bin','WIDTH_FT','WIDTH_IN','WIDTH_bin','SO_CREATED_DATE_Y','SO_CREATED_DATE_M','SO_CREATED_DATE_D','SEASON','REGION','REJECT'])\n",
        "\n",
        "features = features.drop(columns=['REGION_STATE_ID','SO_CREATED_DATE','HEIGHT_FT','HEIGHT_IN','WIDTH_FT','WIDTH_IN','SO_CREATED_DATE_Y','SO_CREATED_DATE_M','SO_CREATED_DATE_D','SO_CREATED_DATE']) #May need to drop more features\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCBEr5CaFu_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bou27Fmg47jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features['REJECT'].value_counts() #0,1 check, data set imbalanced"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN5QttDa4f2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rebalance data set using sklearn resample\n",
        "df_majority = features[features.REJECT==0] #majority of REJECT column\n",
        "df_minority = features[features.REJECT==1] #minority of REJECT column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MPzDGoz4t9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resample data to have minority class equal majority class\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=10374,    # to match majority class\n",
        "                                 random_state=123) # reproducible results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EM39dmm5pgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatenate df_majority and df_minority_upsampled together after rebalance\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX_DAAIy5s8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#verifiction of resampling; 0 and 1 count now equal; data rebalanced\n",
        "df_upsampled.REJECT.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1E96wpC6maR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reassign the resampled data back into the features variable\n",
        "features = df_upsampled\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSAbbCM0FvjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#numeric_features = ['HEIGHT_FT','HEIGHT_IN','WIDTH_FT','WIDTH_IN']\n",
        "#numeric_transformer = Pipeline(steps=[\n",
        "    #('imputer', SimpleImputer(strategy='median')),\n",
        "    #('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['FABRIC_ID','ORIGINAL_MATERIAL_ID','SEASON','REGION','WIDTH_bin','HEIGHT_bin']\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        #('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS-7IU9KIT2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyMjyWnpI7y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers = [\n",
        "    #LogisticRegression(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    XGBClassifier(),\n",
        "    #SVC(kernel='linear', \n",
        "            #class_weight='balanced', # penalize\n",
        "            #probability=True),\n",
        "    #GaussianNB()\n",
        "    #MLPClassifier(),\n",
        "    KNeighborsClassifier()\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhoni-O9JQX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('clf', None)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ5mcVN-KRc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y are the values we want to predict\n",
        "y = np.array(features['REJECT'])\n",
        "# Remove the labels from the features\n",
        "# axis 1 refers to the columns\n",
        "X = features.drop('REJECT', axis = 1)\n",
        "# Saving feature names for later use\n",
        "X_list = list(X.columns)\n",
        "X_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJu4U-gJJV06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx75VPKcJXNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Features Shape:', X_train.shape)\n",
        "print('Training Labels Shape:', y_train.shape)\n",
        "print('Testing Features Shape:', X_test.shape)\n",
        "print('Testing Labels Shape:', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwkbtGvQDNp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_transformer_feature_names(columnTransformer):\n",
        "  output_features = []\n",
        "\n",
        "  for name, pipe, features in columnTransformer.transformers_:\n",
        "    if name!='remainder':\n",
        "      for i in pipe:\n",
        "        trans_features = []\n",
        "        if hasattr(i, 'categories_'):\n",
        "          trans_features.extend(i.get_feature_names(features))\n",
        "        else:\n",
        "          trans_features = features\n",
        "      output_features.extend(trans_features)\n",
        "\n",
        "  return np.array(output_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUyW6ccXJY4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roc_things = []\n",
        "precision_recall_things = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijXvsIl-Ja9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for classifier in classifiers:\n",
        "    clf.set_params(clf=classifier).fit(X_train, y_train)\n",
        "    classifier_name = classifier.__class__.__name__\n",
        "    print(str(classifier))\n",
        "    print('~Model Score: %.3f' % clf.score(X_test, y_test))\n",
        "\n",
        "    y_score = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "    \n",
        "    roc_auc = roc_auc_score(y_test, y_score)\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "    roc_things.append((fpr, tpr, '{} AUC: {:.3f}'.format(classifier_name, roc_auc)))\n",
        "    \n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    precision_recall_things.append((recall, precision, thresholds, '{} AUC: {:.3f}'.format(classifier_name, pr_auc)))\n",
        "    #plot_precision_recall_curve(clf, X_test, y_test)\n",
        "     \n",
        "    feature_names = get_transformer_feature_names(clf.named_steps['preprocessor'])\n",
        "\n",
        "\n",
        "    try:\n",
        "      importances = classifier.feature_importances_\n",
        "      indices = np.argsort(importances)[::-1]\n",
        "      print('~Feature Ranking:')\n",
        "    \n",
        "    \n",
        "\n",
        "      for f in range (X_test.shape[1]):\n",
        "        print ('{}. {} {} ({:.3f})'.format(f + 1, feature_names[indices[f]], indices[f], importances[indices[f]]))\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "\n",
        "    #importances[indices]\n",
        "    #feature_names[indices]\n",
        "\n",
        "    scores = cross_val_score(clf, X, y, cv=5)\n",
        "    print('~Accuracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "    print('~Confusion Matrix:''\\n',\n",
        "    confusion_matrix(y_test, y_pred))\n",
        "    print('~Classification Report:''\\n',\n",
        "    classification_report(y_test, y_pred))\n",
        "   \n",
        "    print('~Average Precision Score: {:.3f}'.format(average_precision_score(y_test, y_score)))\n",
        "    print('~roc_auc_score: {:.3f}'.format(roc_auc))\n",
        "    print('~precision-recall AUC: {:.3f}'.format(pr_auc))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVrnkzY-JsAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ROC Curves summarize the trade-off between the true positive rate and false positive rate for a predictive model using different probability thresholds.\n",
        "roc_plt = plt.figure()\n",
        "lw = 4\n",
        "for roc_thing in roc_things:\n",
        "    fpr, tpr, label = roc_thing\n",
        "    plt.plot(fpr, tpr, lw=lw, label=label)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-5phkGDJv0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Precision-Recall curves summarize the trade-off between the true positive rate and the positive predictive value for a \n",
        "#predictive model using different probability thresholds.\n",
        "pr_plt = plt.figure()\n",
        "for pr_thing in precision_recall_things:\n",
        "    recall, precision, _, label = pr_thing\n",
        "    plt.plot(recall, precision, lw=lw, label=label)\n",
        "ratio = y_test[y_test].shape[0] / y_test.shape[0]\n",
        "plt.hlines(y=ratio, xmin=0, xmax=1, color='navy', lw=lw, linestyle='--')\n",
        "plt.vlines(x=ratio, ymin=0, ymax=1, color='navy', lw=lw, linestyle='--')\n",
        "plt.title('Precision-recall plot')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymoX82GBJxpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import hmean\n",
        "import numpy.ma as ma\n",
        "\n",
        "recall, precision, thresholds, _ = precision_recall_things[1]\n",
        "\n",
        "a = np.column_stack((recall,precision))\n",
        "\n",
        "a = ma.masked_less_equal(a, 0)\n",
        "a = ma.mask_rows(a)\n",
        "f1 = hmean(a,axis=1)\n",
        "\n",
        "threshold_that_maximizes_f1 = thresholds[np.argmax(f1)]\n",
        "print('threshold that optimizes f1: {}'.format(threshold_that_maximizes_f1))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}